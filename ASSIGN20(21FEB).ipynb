{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJNNw5xxMowB6SSSMAtUNT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanishqacodes/DATA-SCIENCE-MASTERS/blob/main/21_FEB_ASS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
        "\n",
        "Web scraping is the process of using bots to extract content and data from a website.\n",
        "\n",
        "Unlike screen scraping, which only copies pixels displayed onscreen, web scraping extracts underlying HTML code and, with it, data stored in a database. The scraper can then replicate entire website content elsewhere.\n",
        "\n",
        "* Search engine bots crawling a site, analyzing its content and then ranking it.\n",
        "* Price comparison sites deploying bots to auto-fetch prices and product descriptions for allied seller websites.\n",
        "* Market research companies using scrapers to pull data from forums and social media (e.g., for sentiment analysis)."
      ],
      "metadata": {
        "id": "sn4pyiX7Rghn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. What are the different methods used for Web Scraping?\n",
        "\n",
        "* Copy-pasting. The manual human examination and copy-pasting method may sometimes prove irreplaceable. At times, this technique may be the only practical method to use especially when websites are setup with barriers and machine automation cannot be enabled.\n",
        "\n",
        "* DOM Parsing. In order to dynamically modify or inspect a web page, client-side scripts parse the contents of the web page into a DOM tree. By embedding a program into the web browser, you can then retrieve the information from the tree.\n",
        "\n",
        "* HTTP Programming. Using socket programming, posting HTTP requests can help one retrieve dynamic as well as static web page information.\n",
        "\n",
        "* Recognizing Semantic Annotation. Most web pages have semantic annotations/markup or metadata that can be easily retrieved. This could be a simple case of DOM parsing if the metadata is just embedded in the web page. Web scrapers can also use the annotations located in the semantic layer of the web page before actually scraping it.\n",
        "\n",
        "* Text Grepping. Using Python programming languages or Perl, one can use the UNIX grep command to extract valuable data and information from web pages.\n",
        "\n",
        "* Web scraping Software. If you do not want to manually use web-scraping codes, you can make use of a software that can do the web scraping for you. It can automatically retrieve the information off the web page, convert it into recognizable information, and store it in a local database.\n"
      ],
      "metadata": {
        "id": "k7xtsIP-SCCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. What is Beautiful Soup? Why is it used?\n",
        "\n",
        "Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files. \n",
        "\n",
        "It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner."
      ],
      "metadata": {
        "id": "Hn-2XHYUSnzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4. Why is flask used in this Web Scraping project?\n",
        "Mainly, Flask is used to create a RESTful API that enables users to interact with the web scraping script.\n",
        "\n",
        "Using Flask to create a RESTful API provides several benefits for this Web Scraping project, including:\n",
        "\n",
        "* Ease of use: Flask is a lightweight and easy-to-use web application framework that makes it simple to create APIs in Python.\n",
        "\n",
        "* Flexibility: Flask provides a flexible way to define API endpoints, making it easy to create and modify endpoints to suit the needs of the project.\n",
        "\n",
        "* Scalability: Flask is well-suited for creating scalable web applications and APIs, making it a good choice for a project like web scraping where there may be a large number of requests to handle.\n",
        "\n",
        "* Integration: Flask can be easily integrated with other libraries and tools in the Python ecosystem, such as Beautiful Soup and Requests, which are commonly used for web scraping.\n"
      ],
      "metadata": {
        "id": "rp2dMHwwS22h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
        "\n",
        "* code pipline :-AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates.\n",
        "\n",
        "* bean  stalk :- AWS Elastic Beanstalk automates the details of capacity provisioning, load balancing, auto scaling, and application deployment, creating an environment that runs a version of your application. "
      ],
      "metadata": {
        "id": "GxcqDUwGT_jV"
      }
    }
  ]
}